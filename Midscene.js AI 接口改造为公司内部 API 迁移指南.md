# Midscene.js AI æ¥å£æ”¹é€ ä¸ºå…¬å¸å†…éƒ¨ API è¿ç§»æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•å°† Midscene.js ä¸­é›†æˆçš„å¤–éƒ¨ AI æœåŠ¡æ¥å£æ”¹é€ ä¸ºå…¬å¸å†…éƒ¨å°è£…çš„ AI APIï¼ŒåŒ…æ‹¬ç°æœ‰æ¶æ„åˆ†æã€æ•°æ®å¤„ç†æµç¨‹ã€æ”¹é€ æ–¹æ¡ˆå’Œå…·ä½“å®ç°ã€‚

---

## ğŸ“Š Part 1: ç°æœ‰ AI æ¥å£æ¶æ„åˆ†æ

### 1.1 å½“å‰ AI æœåŠ¡æ¶æ„å›¾

```mermaid
graph TB
    subgraph "ç”¨æˆ·å±‚"
        U1[agent.aiAction]
        U2[agent.aiQuery]
        U3[agent.aiAssert]
        U4[agent.aiWaitFor]
    end
    
    subgraph "ä¸šåŠ¡é€»è¾‘å±‚"
        B1[TaskExecutor.action]
        B2[Insight.locate]
        B3[Insight.extract]
        B4[setupPlanningContext]
    end
    
    subgraph "AI è°ƒç”¨æ ¸å¿ƒå±‚"
        C1[callAI]
        C2[callAIWithObjectResponse]
        C3[createChatClient]
        C4[æ¶ˆæ¯æ ¼å¼åŒ–]
    end
    
    subgraph "æ¨¡å‹é€‚é…å±‚"
        A1[OpenAI Adapter]
        A2[Anthropic Adapter]
        A3[Qwen-VL Adapter]
        A4[UI-TARS Adapter]
        A5[Gemini Adapter]
    end
    
    subgraph "å¤–éƒ¨ AI æœåŠ¡"
        E1[OpenAI API]
        E2[Anthropic API]
        E3[é˜¿é‡Œäº‘ Qwen API]
        E4[ç«å±±å¼•æ“ Doubao API]
        E5[Google Gemini API]
    end
    
    U1 --> B1
    U2 --> B3
    U3 --> B3
    U4 --> B3
    
    B1 --> B4
    B2 --> C2
    B3 --> C2
    B4 --> C1
    
    C1 --> C3
    C2 --> C1
    C3 --> C4
    
    C3 --> A1
    C3 --> A2
    C3 --> A3
    C3 --> A4
    C3 --> A5
    
    A1 --> E1
    A2 --> E2
    A3 --> E3
    A4 --> E4
    A5 --> E5
    
    style B1 fill:#e1f5fe
    style C1 fill:#fff3e0
    style A1 fill:#f3e5f5
    style E1 fill:#ffcdd2
```

### 1.2 æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### ğŸ”§ AI è°ƒç”¨æ ¸å¿ƒå±‚

**callAI å‡½æ•°** - æ‰€æœ‰ AI è°ƒç”¨çš„ç»Ÿä¸€å…¥å£
- **ä½ç½®**: `packages/core/src/ai-model/service-caller/index.ts`
- **èŒè´£**: ç»Ÿä¸€çš„ AI æœåŠ¡è°ƒç”¨æ¥å£ï¼Œå¤„ç†ä¸åŒæ¨¡å‹çš„é€‚é…
- **è¾“å…¥**: æ¶ˆæ¯æ•°ç»„ã€åŠ¨ä½œç±»å‹ã€æ¨¡å‹é…ç½®
- **è¾“å‡º**: AI å“åº”å†…å®¹å’Œä½¿ç”¨ç»Ÿè®¡

**createChatClient å‡½æ•°** - æ¨¡å‹å®¢æˆ·ç«¯åˆ›å»º
- **èŒè´£**: æ ¹æ®é…ç½®åˆ›å»ºä¸åŒçš„ AI å®¢æˆ·ç«¯ï¼ˆOpenAI SDKã€Anthropic SDKç­‰ï¼‰
- **æ”¯æŒ**: OpenAIã€Azure OpenAIã€Anthropicã€ä»£ç†é…ç½®ç­‰

#### ğŸ›ï¸ æ¨¡å‹é…ç½®ç³»ç»Ÿ

**IModelConfig æ¥å£** - ç»Ÿä¸€çš„æ¨¡å‹é…ç½®ç»“æ„
```typescript
interface IModelConfig {
  modelName: string;              // æ¨¡å‹åç§°
  openaiBaseURL?: string;         // API åŸºç¡€ URL
  openaiApiKey?: string;          // API å¯†é’¥
  vlMode?: TVlModeTypes;          // è§†è§‰è¯­è¨€æ¨¡å‹ç±»å‹
  anthropicApiKey?: string;       // Anthropic API å¯†é’¥
  // ... æ›´å¤šé…ç½®é€‰é¡¹
}
```

---

## ğŸ”„ Part 2: å½“å‰æ•°æ®å¤„ç†æµç¨‹

### 2.1 å®Œæ•´çš„ AI è°ƒç”¨æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·ä»£ç 
    participant Agent as MidsceneAgent
    participant Executor as TaskExecutor
    participant AI as AIè°ƒç”¨å±‚
    participant Client as SDKå®¢æˆ·ç«¯
    participant External as å¤–éƒ¨AIæœåŠ¡
    
    User->>Agent: aiAction("ç‚¹å‡»ç™»å½•æŒ‰é’®")
    Agent->>Executor: æ‰§è¡Œä»»åŠ¡
    Executor->>Executor: è·å–UIä¸Šä¸‹æ–‡
    Note over Executor: åŒ…å«æˆªå›¾Base64æ•°æ®
    
    Executor->>AI: callAIWithObjectResponse(messages, config)
    AI->>AI: æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
    Note over AI: åŒ…å«ç³»ç»Ÿæç¤ºè¯ + æˆªå›¾ + ç”¨æˆ·æŒ‡ä»¤
    
    AI->>Client: createChatClient(config)
    Client->>Client: åˆå§‹åŒ–SDKå®¢æˆ·ç«¯
    Note over Client: OpenAI/Anthropic/etc.
    
    AI->>Client: completion.create(payload)
    Client->>External: HTTP APIè°ƒç”¨
    Note over External: GPT-4V/Claude/Qwen-VLç­‰
    
    External-->>Client: JSONå“åº”
    Client-->>AI: è§£æåçš„ç»“æœ
    AI->>AI: å“åº”æ ¼å¼åŒ–å’ŒéªŒè¯
    AI-->>Executor: å…ƒç´ å®šä½ç»“æœ
    Executor-->>Agent: æ‰§è¡Œç»“æœ
    Agent-->>User: æ“ä½œå®Œæˆ
```

### 2.2 å…³é”®æ•°æ®ç»“æ„

#### ğŸ“¸ UIContext æ•°æ®ç»“æ„
```typescript
interface UIContext {
  tree: ElementTreeNode;          // DOM/UIæ ‘ç»“æ„
  size: { width: number; height: number }; // å±å¹•å°ºå¯¸
  screenshotBase64: string;       // Base64æˆªå›¾æ•°æ®
}
```

#### ğŸ¤– AI æ¶ˆæ¯æ ¼å¼
```typescript
type AIMessage = {
  role: 'system' | 'user';
  content: Array<{
    type: 'text' | 'image_url';
    text?: string;                // æ–‡æœ¬å†…å®¹
    image_url?: {
      url: string;                // data:image/png;base64,... æ ¼å¼
      detail: 'high' | 'low';     // å›¾åƒå¤„ç†è´¨é‡
    };
  }>;
}
```

#### ğŸ“Š AI å“åº”æ ¼å¼
```typescript
interface AIResponse {
  content: string | object;       // å“åº”å†…å®¹
  usage?: {
    prompt_tokens: number;        // è¾“å…¥tokenæ•°
    completion_tokens: number;    // è¾“å‡ºtokenæ•°
    total_tokens: number;         // æ€»tokenæ•°
    time_cost: number;           // è€—æ—¶(ms)
    model_name: string;          // æ¨¡å‹åç§°
  };
}
```

---

## ğŸ—ï¸ Part 3: æ”¹é€ ä¸ºå…¬å¸å†…éƒ¨ API æ–¹æ¡ˆ

### 3.1 æ”¹é€ æ¶æ„è®¾è®¡

```mermaid
graph TB
    subgraph "ç”¨æˆ·å±‚ (æ— å˜åŒ–)"
        U1[agent.aiAction]
        U2[agent.aiQuery]
        U3[agent.aiAssert]
    end
    
    subgraph "ä¸šåŠ¡é€»è¾‘å±‚ (æ— å˜åŒ–)"
        B1[TaskExecutor.action]
        B2[Insight.locate]
        B3[Insight.extract]
    end
    
    subgraph "AI è°ƒç”¨æ ¸å¿ƒå±‚ (è½»å¾®æ”¹é€ )"
        C1[callAI - ä¿æŒä¸å˜]
        C2[createChatClient - éœ€è¦æ”¹é€ ]
        C3[æ¶ˆæ¯æ ¼å¼åŒ– - å¯èƒ½éœ€è¦è°ƒæ•´]
    end
    
    subgraph "ğŸ†• å…¬å¸å†…éƒ¨é€‚é…å±‚"
        N1[InternalAIAdapter]
        N2[æ¶ˆæ¯æ ¼å¼è½¬æ¢å™¨]
        N3[å“åº”æ ¼å¼è½¬æ¢å™¨]
        N4[é”™è¯¯å¤„ç†é€‚é…å™¨]
    end
    
    subgraph "ğŸ¢ å…¬å¸å†…éƒ¨ AI æœåŠ¡"
        I1[å…¬å¸ç»Ÿä¸€AIç½‘å…³]
        I2[å†…éƒ¨æ¨¡å‹è°ƒåº¦å™¨]
        I3[å¤šæ¨¡æ€å¤„ç†æœåŠ¡]
        I4[ç¼“å­˜å’Œé™æµæœåŠ¡]
    end
    
    U1 --> B1
    U2 --> B3
    U3 --> B3
    
    B1 --> B2
    B2 --> C1
    B3 --> C1
    
    C1 --> C2
    C2 --> N1
    C1 --> C3
    C3 --> N2
    
    N1 --> N2
    N2 --> N3
    N3 --> N4
    
    N4 --> I1
    I1 --> I2
    I2 --> I3
    I3 --> I4
    
    style N1 fill:#c8e6c9
    style N2 fill:#c8e6c9
    style N3 fill:#c8e6c9
    style N4 fill:#c8e6c9
    style I1 fill:#ffecb3
```

### 3.2 æ”¹é€ ç­–ç•¥

#### ğŸ¯ æœ€å°ä¾µå…¥åŸåˆ™
- **ä¿æŒç”¨æˆ·APIä¸å˜**: `agent.aiAction()` ç­‰æ¥å£å®Œå…¨ä¸å˜
- **å¤ç”¨ç°æœ‰é€»è¾‘**: ä¸šåŠ¡é€»è¾‘å±‚å’Œå¤§éƒ¨åˆ†æ ¸å¿ƒé€»è¾‘ä¿æŒä¸å˜
- **é€‚é…å™¨æ¨¡å¼**: æ–°å¢é€‚é…å™¨å±‚ï¼Œè€Œä¸æ˜¯ä¿®æ”¹æ ¸å¿ƒä»£ç 

#### ğŸ”„ æ”¹é€ èŒƒå›´
1. **createChatClient å‡½æ•°**: æ–°å¢å†…éƒ¨ API å®¢æˆ·ç«¯åˆ›å»ºé€»è¾‘
2. **æ¶ˆæ¯æ ¼å¼é€‚é…**: å¯èƒ½éœ€è¦è°ƒæ•´æ¶ˆæ¯æ ¼å¼ä»¥åŒ¹é…å†…éƒ¨ API
3. **å“åº”è§£æ**: é€‚é…å†…éƒ¨ API çš„å“åº”æ ¼å¼
4. **é…ç½®ç³»ç»Ÿ**: æ–°å¢å†…éƒ¨ API ç›¸å…³é…ç½®é€‰é¡¹

---

## ğŸ’» Part 4: å…·ä½“å®ç°æ–¹æ¡ˆ

### 4.1 æ–°å¢é…ç½®é€‰é¡¹

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# å…¬å¸å†…éƒ¨ AI æœåŠ¡é…ç½®
MIDSCENE_USE_INTERNAL_AI=1                    # å¯ç”¨å†…éƒ¨AIæœåŠ¡
MIDSCENE_INTERNAL_AI_BASE_URL="https://ai-api.company.com/v1"
MIDSCENE_INTERNAL_AI_API_KEY="your-internal-api-key"
MIDSCENE_INTERNAL_AI_MODEL_NAME="company-vlm-v1.0"
MIDSCENE_INTERNAL_AI_TIMEOUT=30000            # è¶…æ—¶æ—¶é—´(ms)
```

#### TypeScript ç±»å‹å®šä¹‰
```typescript
// packages/shared/src/env/types.ts
export const MIDSCENE_USE_INTERNAL_AI = 'MIDSCENE_USE_INTERNAL_AI';
export const MIDSCENE_INTERNAL_AI_BASE_URL = 'MIDSCENE_INTERNAL_AI_BASE_URL';
export const MIDSCENE_INTERNAL_AI_API_KEY = 'MIDSCENE_INTERNAL_AI_API_KEY';
export const MIDSCENE_INTERNAL_AI_MODEL_NAME = 'MIDSCENE_INTERNAL_AI_MODEL_NAME';
export const MIDSCENE_INTERNAL_AI_TIMEOUT = 'MIDSCENE_INTERNAL_AI_TIMEOUT';

// æ‰©å±•æ¨¡å‹é…ç½®æ¥å£
interface IModelConfig {
  // ... ç°æœ‰é…ç½®
  useInternalAI?: boolean;
  internalAIBaseURL?: string;
  internalAIApiKey?: string;
  internalAIModelName?: string;
  internalAITimeout?: number;
}
```

### 4.2 å†…éƒ¨ AI é€‚é…å™¨å®ç°

#### ä¸»é€‚é…å™¨ç±»
```typescript
// packages/core/src/ai-model/internal-ai-adapter.ts
import { getDebug } from '@midscene/shared/logger';
import type { IModelConfig } from '@midscene/shared/env';
import type { AIArgs, AIActionType } from './common';

const debug = getDebug('ai:internal-adapter');

export class InternalAIAdapter {
  private baseURL: string;
  private apiKey: string;
  private modelName: string;
  private timeout: number;

  constructor(config: IModelConfig) {
    this.baseURL = config.internalAIBaseURL!;
    this.apiKey = config.internalAIApiKey!;
    this.modelName = config.internalAIModelName!;
    this.timeout = config.internalAITimeout || 30000;
  }

  async create(params: {
    messages: AIArgs;
    actionType: AIActionType;
    stream?: boolean;
  }) {
    const { messages, actionType, stream = false } = params;
    
    debug('Calling internal AI service', {
      model: this.modelName,
      actionType,
      messageCount: messages.length
    });

    // 1. è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸ºå†…éƒ¨APIæ ¼å¼
    const internalMessages = this.convertMessagesToInternalFormat(messages);
    
    // 2. æ„å»ºè¯·æ±‚è½½è·
    const requestPayload = {
      model: this.modelName,
      messages: internalMessages,
      action_type: this.mapActionType(actionType),
      stream,
      max_tokens: 2048,
      temperature: 0.1,
    };

    // 3. å‘é€HTTPè¯·æ±‚
    const response = await this.sendRequest(requestPayload, stream);
    
    // 4. è½¬æ¢å“åº”æ ¼å¼
    return this.convertResponseToOpenAIFormat(response);
  }

  private convertMessagesToInternalFormat(messages: AIArgs) {
    return messages.map(msg => {
      if (msg.role === 'system') {
        return {
          role: 'system',
          content: msg.content as string
        };
      }
      
      if (Array.isArray(msg.content)) {
        // å¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯
        const content = msg.content.map(item => {
          if (item.type === 'text') {
            return {
              type: 'text',
              text: item.text
            };
          } else if (item.type === 'image_url') {
            // è½¬æ¢å›¾åƒæ ¼å¼ - å¯èƒ½éœ€è¦æ ¹æ®å†…éƒ¨APIæ ¼å¼è°ƒæ•´
            return {
              type: 'image',
              image_data: {
                url: item.image_url!.url,
                detail: item.image_url!.detail || 'high'
              }
            };
          }
          return item;
        });
        
        return {
          role: msg.role,
          content
        };
      }
      
      return {
        role: msg.role,
        content: msg.content as string
      };
    });
  }

  private mapActionType(actionType: AIActionType): string {
    // å°† Midscene çš„åŠ¨ä½œç±»å‹æ˜ å°„åˆ°å†…éƒ¨APIçš„ç±»å‹
    const mapping = {
      [AIActionType.ASSERT]: 'assertion',
      [AIActionType.INSPECT_ELEMENT]: 'element_location',
      [AIActionType.EXTRACT_DATA]: 'data_extraction',
      [AIActionType.PLAN]: 'action_planning',
      [AIActionType.DESCRIBE_ELEMENT]: 'element_description',
      [AIActionType.TEXT]: 'text_generation'
    };
    return mapping[actionType] || 'general';
  }

  private async sendRequest(payload: any, stream: boolean) {
    const url = `${this.baseURL}/chat/completions`;
    
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
        'X-Source': 'midscene-js',
        'X-Version': '1.0'
      },
      body: JSON.stringify(payload),
    });

    if (!response.ok) {
      throw new Error(`Internal AI API error: ${response.status} ${response.statusText}`);
    }

    if (stream) {
      return response; // è¿”å›æµå“åº”
    } else {
      return await response.json();
    }
  }

  private convertResponseToOpenAIFormat(response: any) {
    // å°†å†…éƒ¨APIå“åº”è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
    if (response.choices && response.choices[0]) {
      return {
        choices: [{
          message: {
            content: response.choices[0].message?.content || response.choices[0].text
          }
        }],
        usage: {
          prompt_tokens: response.usage?.input_tokens || response.usage?.prompt_tokens || 0,
          completion_tokens: response.usage?.output_tokens || response.usage?.completion_tokens || 0,
          total_tokens: response.usage?.total_tokens || 0
        },
        _request_id: response.request_id || response.id
      };
    }
    
    throw new Error('Invalid response format from internal AI service');
  }
}
```

### 4.3 ä¿®æ”¹æ ¸å¿ƒè°ƒç”¨å‡½æ•°

#### æ”¹é€  createChatClient å‡½æ•°
```typescript
// packages/core/src/ai-model/service-caller/index.ts
import { InternalAIAdapter } from './internal-ai-adapter';

async function createChatClient({
  AIActionTypeValue,
  modelConfig,
}: {
  AIActionTypeValue: AIActionType;
  modelConfig: IModelConfig;
}): Promise<{
  completion: any; // å¯ä»¥æ˜¯ OpenAI.Chat.Completions æˆ– InternalAIAdapter
  style: 'openai' | 'anthropic' | 'internal';
  modelName: string;
  modelDescription: string;
  // ... å…¶ä»–è¿”å›å€¼
}> {
  // ... ç°æœ‰ä»£ç  ...

  // ğŸ†• æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦ä½¿ç”¨å†…éƒ¨AIæœåŠ¡
  if (modelConfig.useInternalAI) {
    const internalAdapter = new InternalAIAdapter(modelConfig);
    
    return {
      completion: internalAdapter,
      style: 'internal' as const,
      modelName: modelConfig.internalAIModelName!,
      modelDescription: `Internal AI Model: ${modelConfig.internalAIModelName}`,
      vlMode: 'internal' as any, // å¯èƒ½éœ€è¦æ–°å¢ç±»å‹
    };
  }

  // ... ç°æœ‰çš„ OpenAIã€Anthropic ç­‰é€»è¾‘ä¿æŒä¸å˜ ...
}
```

#### æ”¹é€  callAI å‡½æ•°
```typescript
// packages/core/src/ai-model/service-caller/index.ts
export async function callAI(
  messages: ChatCompletionMessageParam[],
  AIActionTypeValue: AIActionType,
  modelConfig: IModelConfig,
  options?: {
    stream?: boolean;
    onChunk?: StreamingCallback;
  },
): Promise<{ content: string; usage?: AIUsageInfo; isStreamed: boolean }> {
  const {
    completion,
    style,
    modelName,
    modelDescription,
    // ... å…¶ä»–è§£æ„å€¼
  } = await createChatClient({
    AIActionTypeValue,
    modelConfig,
  });

  // ... ç°æœ‰å˜é‡å£°æ˜ ...

  try {
    if (style === 'openai') {
      // ... ç°æœ‰ OpenAI å¤„ç†é€»è¾‘ ...
    } else if (style === 'anthropic') {
      // ... ç°æœ‰ Anthropic å¤„ç†é€»è¾‘ ...
    } else if (style === 'internal') {
      // ğŸ†• æ–°å¢ï¼šå¤„ç†å†…éƒ¨AIæœåŠ¡è°ƒç”¨
      debugCall(`sending request to internal AI service: ${modelName}`);
      
      const result = await (completion as InternalAIAdapter).create({
        messages: messages as any,
        actionType: AIActionTypeValue,
        stream: isStreaming,
      });
      
      timeCost = Date.now() - startTime;
      
      debugProfileStats(
        `internal-ai, ${modelName}, prompt-tokens, ${result.usage?.prompt_tokens || ''}, completion-tokens, ${result.usage?.completion_tokens || ''}, total-tokens, ${result.usage?.total_tokens || ''}, cost-ms, ${timeCost}`
      );
      
      content = result.choices[0].message.content;
      usage = result.usage;
    }

    // ... ç°æœ‰çš„è¿”å›é€»è¾‘ä¿æŒä¸å˜ ...
  } catch (e: any) {
    // ... ç°æœ‰é”™è¯¯å¤„ç†ï¼Œå¯èƒ½éœ€è¦é’ˆå¯¹å†…éƒ¨APIè°ƒæ•´é”™è¯¯ä¿¡æ¯ ...
  }
}
```

---

## ğŸš€ Part 5: éƒ¨ç½²å’Œæµ‹è¯•

### 5.1 æ¸è¿›å¼è¿ç§»ç­–ç•¥

```mermaid
graph LR
    subgraph "é˜¶æ®µ1: å¹¶è¡Œæµ‹è¯•"
        A1[ä¿æŒç°æœ‰å¤–éƒ¨API]
        A2[æ–°å¢å†…éƒ¨APIé€‚é…å™¨]
        A3[é…ç½®å¼€å…³æ§åˆ¶]
    end
    
    subgraph "é˜¶æ®µ2: é€æ­¥åˆ‡æ¢"
        B1[å°èŒƒå›´å¯ç”¨å†…éƒ¨API]
        B2[ç›‘æ§æ€§èƒ½å’Œå‡†ç¡®ç‡]
        B3[é€æ­¥æ‰©å¤§èŒƒå›´]
    end
    
    subgraph "é˜¶æ®µ3: å®Œå…¨è¿ç§»"
        C1[å…¨é¢åˆ‡æ¢åˆ°å†…éƒ¨API]
        C2[ç§»é™¤å¤–éƒ¨APIä¾èµ–]
        C3[æ¸…ç†å†—ä½™ä»£ç ]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    B1 --> C1
    B2 --> C1
    B3 --> C1
    
    style A2 fill:#c8e6c9
    style B2 fill:#fff3e0
    style C1 fill:#ffcdd2
```

### 5.2 é…ç½®ç¤ºä¾‹

#### å¼€å‘ç¯å¢ƒé…ç½®
```bash
# .env.development
MIDSCENE_USE_INTERNAL_AI=1
MIDSCENE_INTERNAL_AI_BASE_URL="https://ai-api-dev.company.com/v1"
MIDSCENE_INTERNAL_AI_API_KEY="dev-api-key-12345"
MIDSCENE_INTERNAL_AI_MODEL_NAME="company-vlm-dev"
MIDSCENE_INTERNAL_AI_TIMEOUT=45000

# è°ƒè¯•å¼€å…³
DEBUG=midscene:ai:internal-adapter,midscene:ai:profile:stats
```

#### ç”Ÿäº§ç¯å¢ƒé…ç½®
```bash
# .env.production
MIDSCENE_USE_INTERNAL_AI=1
MIDSCENE_INTERNAL_AI_BASE_URL="https://ai-api.company.com/v1"
MIDSCENE_INTERNAL_AI_API_KEY="${AI_API_KEY_FROM_SECRET_MANAGER}"
MIDSCENE_INTERNAL_AI_MODEL_NAME="company-vlm-v2.0"
MIDSCENE_INTERNAL_AI_TIMEOUT=30000
```

### 5.3 æµ‹è¯•éªŒè¯

#### å•å…ƒæµ‹è¯•
```typescript
// packages/core/tests/ai/internal-ai-adapter.test.ts
import { InternalAIAdapter } from '@/ai-model/internal-ai-adapter';
import { AIActionType } from '@/ai-model/common';

describe('InternalAIAdapter', () => {
  const mockConfig = {
    useInternalAI: true,
    internalAIBaseURL: 'https://test-api.company.com/v1',
    internalAIApiKey: 'test-key',
    internalAIModelName: 'test-model',
  };

  it('should convert messages to internal format correctly', async () => {
    const adapter = new InternalAIAdapter(mockConfig);
    const messages = [
      { role: 'system', content: 'You are an AI assistant' },
      {
        role: 'user',
        content: [
          { type: 'text', text: 'Find the login button' },
          { 
            type: 'image_url', 
            image_url: { url: 'data:image/png;base64,abc123', detail: 'high' }
          }
        ]
      }
    ];

    // Mock fetch
    global.fetch = jest.fn().mockResolvedValue({
      ok: true,
      json: () => Promise.resolve({
        choices: [{ message: { content: '{"elements":[{"bbox":[100,200,150,250]}]}' }}],
        usage: { prompt_tokens: 100, completion_tokens: 50, total_tokens: 150 }
      })
    });

    const result = await adapter.create({
      messages: messages as any,
      actionType: AIActionType.INSPECT_ELEMENT
    });

    expect(result.choices[0].message.content).toBeDefined();
    expect(result.usage.total_tokens).toBe(150);
  });
});
```

#### é›†æˆæµ‹è¯•
```typescript
// packages/core/tests/ai/internal-ai-integration.test.ts
describe('Internal AI Integration', () => {
  it('should work end-to-end with internal AI', async () => {
    const agent = new AndroidAgent({
      model: {
        useInternalAI: true,
        internalAIBaseURL: process.env.TEST_INTERNAL_AI_URL,
        internalAIApiKey: process.env.TEST_INTERNAL_AI_KEY,
        internalAIModelName: 'test-model',
      }
    });

    // æ‰§è¡Œå®é™…çš„ AI æ“ä½œ
    const result = await agent.aiAction('ç‚¹å‡»ç™»å½•æŒ‰é’®');
    expect(result).toBeDefined();
  });
});
```

---

## ğŸ“‹ Part 6: ç›‘æ§å’Œç»´æŠ¤

### 6.1 æ€§èƒ½ç›‘æ§

#### å…³é”®æŒ‡æ ‡
- **å“åº”æ—¶é—´**: å†…éƒ¨API vs å¤–éƒ¨APIçš„å“åº”æ—¶é—´å¯¹æ¯”
- **æˆåŠŸç‡**: APIè°ƒç”¨æˆåŠŸç‡
- **Tokenä½¿ç”¨é‡**: è¾“å…¥è¾“å‡ºtokenç»Ÿè®¡
- **é”™è¯¯ç‡**: å„ç±»é”™è¯¯çš„åˆ†å¸ƒ

#### ç›‘æ§å®ç°
```typescript
// packages/core/src/ai-model/monitoring.ts
export class AIServiceMonitor {
  private metrics = {
    requestCount: 0,
    successCount: 0,
    errorCount: 0,
    totalResponseTime: 0,
    tokenUsage: { input: 0, output: 0 }
  };

  recordRequest(startTime: number, success: boolean, usage?: any) {
    this.metrics.requestCount++;
    this.metrics.totalResponseTime += Date.now() - startTime;
    
    if (success) {
      this.metrics.successCount++;
      if (usage) {
        this.metrics.tokenUsage.input += usage.prompt_tokens || 0;
        this.metrics.tokenUsage.output += usage.completion_tokens || 0;
      }
    } else {
      this.metrics.errorCount++;
    }
  }

  getMetrics() {
    return {
      ...this.metrics,
      averageResponseTime: this.metrics.totalResponseTime / this.metrics.requestCount,
      successRate: this.metrics.successCount / this.metrics.requestCount,
    };
  }
}
```

### 6.2 æ•…éšœå¤„ç†

#### é™çº§ç­–ç•¥
```typescript
// packages/core/src/ai-model/fallback-strategy.ts
export class AIServiceFallback {
  async callWithFallback(
    messages: any[],
    actionType: AIActionType,
    modelConfig: IModelConfig
  ) {
    try {
      // 1. ä¼˜å…ˆä½¿ç”¨å†…éƒ¨API
      if (modelConfig.useInternalAI) {
        return await this.callInternalAI(messages, actionType, modelConfig);
      }
    } catch (error) {
      console.warn('Internal AI service failed, falling back to external:', error);
      
      // 2. é™çº§åˆ°å¤–éƒ¨API
      const fallbackConfig = {
        ...modelConfig,
        useInternalAI: false,
        // ä½¿ç”¨å¤‡ç”¨çš„å¤–éƒ¨APIé…ç½®
      };
      
      return await this.callExternalAI(messages, actionType, fallbackConfig);
    }
  }
}
```

---

## âœ… Part 7: æ€»ç»“å’Œæ£€æŸ¥æ¸…å•

### 7.1 æ”¹é€ è¦ç‚¹æ€»ç»“

1. **æœ€å°ä¾µå…¥**: ç”¨æˆ·APIä¿æŒå®Œå…¨ä¸å˜
2. **é€‚é…å™¨æ¨¡å¼**: æ–°å¢å†…éƒ¨APIé€‚é…å™¨ï¼Œä¸ç ´åç°æœ‰æ¶æ„
3. **é…ç½®é©±åŠ¨**: é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ä½¿ç”¨å†…éƒ¨æˆ–å¤–éƒ¨API
4. **æ¸è¿›è¿ç§»**: æ”¯æŒå¹¶è¡Œæµ‹è¯•å’Œåˆ†é˜¶æ®µåˆ‡æ¢
5. **æ•…éšœé™çº§**: å†…éƒ¨APIæ•…éšœæ—¶è‡ªåŠ¨é™çº§åˆ°å¤–éƒ¨API

### 7.2 å®æ–½æ£€æŸ¥æ¸…å•

#### âœ… å¼€å‘é˜¶æ®µ
- [ ] æ–°å¢å†…éƒ¨APIç›¸å…³ç¯å¢ƒå˜é‡å®šä¹‰
- [ ] å®ç° `InternalAIAdapter` ç±»
- [ ] ä¿®æ”¹ `createChatClient` å’Œ `callAI` å‡½æ•°
- [ ] æ·»åŠ æ¶ˆæ¯æ ¼å¼è½¬æ¢é€»è¾‘
- [ ] å®ç°å“åº”æ ¼å¼é€‚é…
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

#### âœ… æµ‹è¯•é˜¶æ®µ
- [ ] åœ¨å¼€å‘ç¯å¢ƒéªŒè¯å†…éƒ¨APIè¿é€šæ€§
- [ ] å¯¹æ¯”å†…éƒ¨APIå’Œå¤–éƒ¨APIçš„å“åº”è´¨é‡
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µæµ‹è¯•
- [ ] å¹¶å‘å’Œå‹åŠ›æµ‹è¯•

#### âœ… éƒ¨ç½²é˜¶æ®µ
- [ ] é…ç½®ç”Ÿäº§ç¯å¢ƒçš„å†…éƒ¨APIæœåŠ¡
- [ ] è®¾ç½®ç›‘æ§å’Œå‘Šè­¦
- [ ] å‡†å¤‡å›æ»šæ–¹æ¡ˆ
- [ ] å°èŒƒå›´ç°åº¦æµ‹è¯•
- [ ] é€æ­¥æ‰©å¤§ä½¿ç”¨èŒƒå›´

#### âœ… ç»´æŠ¤é˜¶æ®µ
- [ ] ç›‘æ§å…³é”®æ€§èƒ½æŒ‡æ ‡
- [ ] å®šæœŸæ£€æŸ¥APIå¯ç”¨æ€§
- [ ] ä¼˜åŒ–å†…éƒ¨APIå“åº”è´¨é‡
- [ ] æ–‡æ¡£æ›´æ–°å’Œå›¢é˜ŸåŸ¹è®­

### 7.3 é¢„æœŸæ”¶ç›Š

- **æˆæœ¬æ§åˆ¶**: å‡å°‘å¤–éƒ¨APIè°ƒç”¨è´¹ç”¨
- **æ•°æ®å®‰å…¨**: æ•æ„Ÿæ•°æ®ä¸å‡ºå…¬å¸ç½‘ç»œ
- **å®šåˆ¶ä¼˜åŒ–**: é’ˆå¯¹ä¸šåŠ¡åœºæ™¯ä¼˜åŒ–æ¨¡å‹
- **æœåŠ¡ç¨³å®š**: å‡å°‘å¯¹å¤–éƒ¨æœåŠ¡çš„ä¾èµ–
- **åˆè§„è¦æ±‚**: æ»¡è¶³æ•°æ®æœ¬åœ°åŒ–è¦æ±‚

é€šè¿‡ä»¥ä¸Šæ–¹æ¡ˆï¼Œå¯ä»¥åœ¨ä¿æŒ Midscene.js ç”¨æˆ·ä½“éªŒä¸å˜çš„å‰æä¸‹ï¼Œå¹³æ»‘åœ°å°†AIæœåŠ¡è¿ç§»åˆ°å…¬å¸å†…éƒ¨ï¼Œå®ç°æ›´å¥½çš„æˆæœ¬æ§åˆ¶å’Œæ•°æ®å®‰å…¨ã€‚
